[project]
name = "flowstate-nodes"
description = "A collection of custom nodes to consolidate functionality of many other nodes, enable unified workflows, and add custom functionality you won't find with other nodes."
version = "1.1.1"
license = {file = "LICENSE"}
dependencies = [
    "transformers>=4.0.0",
    "torch>=1.7.1",
    "accelerate",
    "bitsandbytes>=0.43.0",
    "# llama-cpp-python (CPU only, AVX2)",
    "https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.89+cpuavx2-cp311-cp311-linux_x86_64.whl; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"",
    "https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.89+cpuavx2-cp310-cp310-linux_x86_64.whl; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.10\"",
    "https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.89+cpuavx2-cp311-cp311-win_amd64.whl; platform_system == \"Windows\" and python_version == \"3.11\"",
    "https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.89+cpuavx2-cp310-cp310-win_amd64.whl; platform_system == \"Windows\" and python_version == \"3.10\"",
    "# llama-cpp-python (CUDA, no tensor cores)",
    "https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.89+cu121-cp311-cp311-win_amd64.whl; platform_system == \"Windows\" and python_version == \"3.11\"",
    "https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.89+cu121-cp310-cp310-win_amd64.whl; platform_system == \"Windows\" and python_version == \"3.10\"",
    "https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.89+cu121-cp311-cp311-linux_x86_64.whl; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"",
    "https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.89+cu121-cp310-cp310-linux_x86_64.whl; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.10\""
]

[project.urls]
Repository = "https://github.com/flowstateeng/FlowState-Nodes"
#  Used by Comfy Registry https://comfyregistry.org

[tool.comfy]
PublisherId = "flowstateeng"
DisplayName = "FlowState-Nodes"
Icon = "./imgs/FS-Logo.png"
